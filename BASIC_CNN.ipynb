{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BASIC CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashdhanpal/Pnemonia_Detection_CV_Deep_Learning/blob/main/BASIC_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uAYLzgj0uKE"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-KvixwB042y",
        "outputId": "9475d9e8-f5e9-439e-801d-2c86009ea7df"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\ajith'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIDJcVCY0_XA"
      },
      "source": [
        "# General libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Deep learning libraries\n",
        "import keras.backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Setting seeds for reproducibility\n",
        "seed = 232\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK1Tjx8j1WEk"
      },
      "source": [
        "input_path = 'rsna-pneumonia-detection-challenge/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNo7QUXp240Z",
        "outputId": "8427627d-9b78-4373-8080-51b15c592a0e"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Volume in drive C is AJITH\n",
            " Volume Serial Number is 8ABB-AD60\n",
            "\n",
            " Directory of C:\\Users\\ajith\n",
            "\n",
            "21-11-2020  12:40    <DIR>          .\n",
            "21-11-2020  12:40    <DIR>          ..\n",
            "20-12-2019  21:11    <DIR>          .anaconda\n",
            "07-06-2020  16:03    <DIR>          .conda\n",
            "02-01-2020  20:54                43 .condarc\n",
            "21-11-2020  10:00    <DIR>          .config\n",
            "07-11-2020  14:36    <DIR>          .ipynb_checkpoints\n",
            "25-12-2019  18:58    <DIR>          .ipython\n",
            "19-07-2020  13:56    <DIR>          .jupyter\n",
            "11-10-2020  16:05    <DIR>          .keras\n",
            "02-01-2020  21:01    <DIR>          .matplotlib\n",
            "23-01-2020  20:19    <DIR>          .Origin\n",
            "20-12-2019  21:15    <DIR>          .PyCharmCE2019.3\n",
            "07-11-2020  13:41               244 .python_history\n",
            "23-01-2020  20:19    <DIR>          .QtWebEngineProcess\n",
            "07-06-2020  16:03    <DIR>          .surprise_data\n",
            "19-07-2020  13:55             8,058 0.0.7\n",
            "17-11-2020  21:32    <DIR>          3D Objects\n",
            "05-11-2020  19:59    <DIR>          Apple\n",
            "02-01-2020  20:59            24,729 Automobile.csv\n",
            "15-03-2020  13:48           211,884 Bank_Personal_Loan_Modelling.csv\n",
            "07-11-2020  16:53           209,477 ComputerVision_CapstoneProject.ipynb\n",
            "17-05-2020  11:04            41,415 concrete.csv\n",
            "17-11-2020  21:32    <DIR>          Contacts\n",
            "05-04-2020  17:42            40,697 Data - Parkinsons\n",
            "19-11-2020  21:20    <DIR>          Desktop\n",
            "18-11-2020  15:59    <DIR>          Documents\n",
            "19-11-2020  21:20    <DIR>          Downloads\n",
            "07-11-2020  14:24         3,068,036 ensemble techniques.ipynb\n",
            "17-11-2020  21:32    <DIR>          Favorites\n",
            "17-05-2020  17:49         2,161,046 Feature Engineering project.ipynb\n",
            "06-02-2020  20:04           427,019 healthcare.ipynb\n",
            "03-02-2020  20:31            55,628 insurance.csv\n",
            "17-11-2020  21:32    <DIR>          Links\n",
            "07-06-2020  16:11        26,305,277 ml-100k\n",
            "17-11-2020  21:32    <DIR>          Music\n",
            "05-04-2020  17:42             3,080 names\n",
            "07-06-2020  16:17        26,305,277 newdata\n",
            "19-07-2020  10:58               925 NN Project.ipynb\n",
            "27-12-2019  09:52            21,423 numpy.ipynb\n",
            "21-11-2020  06:10    <DIR>          OneDrive\n",
            "27-12-2019  10:07           137,534 pandas.ipynb\n",
            "26-04-2020  17:46           465,048 PCA.ipynb\n",
            "17-11-2020  21:32    <DIR>          Pictures\n",
            "16-02-2020  14:46            23,823 pima-indians-diabetes.csv\n",
            "23-08-2020  16:55           143,444 Project UNET.ipynb\n",
            "06-09-2020  12:11    <DIR>          PycharmProjects\n",
            "07-11-2020  01:53    <DIR>          pydicom\n",
            "07-06-2020  14:13       318,766,497 ratings_Electronics.csv\n",
            "07-06-2020  19:37         4,343,233 recommandations project.ipynb\n",
            "07-06-2020  14:37             2,417 recommendations project.ipynb\n",
            "21-11-2020  10:01    <DIR>          rsna-pneumonia-detection-challenge\n",
            "18-11-2020  16:12     3,935,364,308 rsna-pneumonia-detection-challenge.zip\n",
            "17-11-2020  21:32    <DIR>          Saved Games\n",
            "17-11-2020  21:32    <DIR>          Searches\n",
            "26-04-2020  15:45            90,381 supervised learning project.ipynb\n",
            "15-03-2020  16:35            89,453 supervised learning projet.ipynb\n",
            "26-04-2020  18:09         4,755,750 Unsupervised learning project.ipynb\n",
            "07-11-2020  14:36            97,214 Untitled.ipynb\n",
            "21-11-2020  12:40           723,284 Untitled1.ipynb\n",
            "26-04-2020  15:10            55,762 vehicle-1.csv\n",
            "17-11-2020  21:32    <DIR>          Videos\n",
            "              31 File(s)  4,323,942,406 bytes\n",
            "              31 Dir(s)  263,460,323,328 bytes free\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7Uoy6Vg2__I",
        "outputId": "62a7c071-7881-47c3-ca5b-bbe4c46d7184"
      },
      "source": [
        "from os import path \n",
        "input_path+'stage_2_train_images'\n",
        "path.isfile(input_path+'stage_2_train_images/'+'2c781913-5f24-4b0e-959c-6b7385c6fce0.dcm')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG2YI50547YN"
      },
      "source": [
        "def process_data(img_dims, batch_size):\n",
        "    # Data generation objects\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n",
        "    test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    # This is fed to the network in the specified batch sizes and image dimensions\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "    directory=input_path+'train', \n",
        "    target_size=(img_dims, img_dims), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='binary', \n",
        "    shuffle=True)\n",
        "\n",
        "    test_gen = test_val_datagen.flow_from_directory(\n",
        "    directory=input_path+'test-1', \n",
        "    target_size=(img_dims, img_dims), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='binary', \n",
        "    shuffle=True)\n",
        "    \n",
        "    return train_gen, test_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMf90ifU5G6B",
        "outputId": "dd17fdb9-ea44-4f2a-ed4f-d04a40edf253"
      },
      "source": [
        "\n",
        "# Hyperparameters\n",
        "img_dims = 150\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Getting the data\n",
        "train_gen, test_gen = process_data(img_dims, batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25803 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrqj3qOcvk79",
        "outputId": "d516b35f-47e1-4d44-8d70-683b09175cf1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x1c9be29c608>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5IQ_vcy5JCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799c175d-6f59-4478-c22f-1ff17b165c19"
      },
      "source": [
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(img_dims, img_dims, 3))\n",
        "\n",
        "# First conv block\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Second conv block\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Third conv block\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Fourth conv block\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "# Fifth conv block\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "\n",
        "# FC layer\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(rate=0.7)(x)\n",
        "x = Dense(units=128, activation='relu')(x)\n",
        "x = Dropout(rate=0.5)(x)\n",
        "x = Dense(units=64, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(units=1, activation='sigmoid')(x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Y9FC636d5q"
      },
      "source": [
        "# Creating model and compiling\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwPrQwoy6gTl"
      },
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQaNF-LX6iHN",
        "outputId": "7af352fc-455e-4583-936b-6d1781064717"
      },
      "source": [
        "# Fitting the model\n",
        "hist = model.fit_generator(\n",
        "           train_gen, steps_per_epoch=train_gen.samples // batch_size, \n",
        "           epochs=epochs, validation_data=test_gen, \n",
        "           validation_steps=test_gen.samples // batch_size, callbacks=[checkpoint, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "806/806 [==============================] - 899s 1s/step - loss: 0.4659 - accuracy: 0.7893 - val_loss: 0.5959 - val_accuracy: 0.7533\n",
            "Epoch 2/10\n",
            "806/806 [==============================] - 729s 905ms/step - loss: 0.4532 - accuracy: 0.7953 - val_loss: 0.5573 - val_accuracy: 0.5321\n",
            "Epoch 3/10\n",
            "806/806 [==============================] - 710s 881ms/step - loss: 0.4402 - accuracy: 0.7980 - val_loss: 0.7665 - val_accuracy: 0.3851\n",
            "Epoch 4/10\n",
            "806/806 [==============================] - 641s 795ms/step - loss: 0.4332 - accuracy: 0.8027 - val_loss: 0.6992 - val_accuracy: 0.3801\n",
            "Epoch 5/10\n",
            "806/806 [==============================] - 505s 627ms/step - loss: 0.4313 - accuracy: 0.8005 - val_loss: 0.6667 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "Epoch 6/10\n",
            "806/806 [==============================] - 502s 622ms/step - loss: 0.4095 - accuracy: 0.8123 - val_loss: 0.6284 - val_accuracy: 0.5186\n",
            "Epoch 7/10\n",
            "806/806 [==============================] - 588s 729ms/step - loss: 0.4068 - accuracy: 0.8115 - val_loss: 0.5322 - val_accuracy: 0.5693\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "Epoch 8/10\n",
            "806/806 [==============================] - 657s 815ms/step - loss: 0.4005 - accuracy: 0.8164 - val_loss: 0.6538 - val_accuracy: 0.5304\n",
            "Epoch 9/10\n",
            "806/806 [==============================] - 646s 801ms/step - loss: 0.3972 - accuracy: 0.8189 - val_loss: 0.6144 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "Epoch 10/10\n",
            "806/806 [==============================] - 618s 767ms/step - loss: 0.3974 - accuracy: 0.8174 - val_loss: 0.5992 - val_accuracy: 0.6115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkTFQpyWqrJ"
      },
      "source": [
        "\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "\n",
        "    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n",
        "        for img in (os.listdir(input_path + 'test-1' + cond)):\n",
        "            img = plt.imread(input_path+'test-1'+cond+img)\n",
        "            img = cv2.resize(img, (img_dims, img_dims))\n",
        "            img = np.dstack([img, img, img])\n",
        "            img = img.astype('float32') / 255\n",
        "            if cond=='/NORMAL/':\n",
        "                label = 0\n",
        "            elif cond=='/PNEUMONIA/':\n",
        "                label = 1\n",
        "            test_data.append(img)\n",
        "            test_labels.append(label)\n",
        "        \n",
        "    test_data = np.array(test_data)\n",
        "    test_labels = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeU5lHtO6mwd",
        "outputId": "f2119ccc-e666-4570-fc84-dd8056bf4eff"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "preds = model.predict(test_data)\n",
        "\n",
        "acc = accuracy_score(test_labels, np.round(preds))*100\n",
        "cm = confusion_matrix(test_labels, np.round(preds))\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print('CONFUSION MATRIX ------------------')\n",
        "print(cm)\n",
        "\n",
        "print('\\nTEST METRICS ----------------------')\n",
        "precision = tp/(tp+fp)*100\n",
        "recall = tp/(tp+fn)*100\n",
        "print('Accuracy: {}%'.format(acc))\n",
        "print('Precision: {}%'.format(precision))\n",
        "print('Recall: {}%'.format(recall))\n",
        "print('F1-score: {}'.format(2*precision*recall/(precision+recall)))\n",
        "\n",
        "print('\\nTRAIN METRIC ----------------------')\n",
        "print('Train acc: {}'.format(np.round((hist.history['accuracy'][-1])*100, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONFUSION MATRIX ------------------\n",
            "[[230   4]\n",
            " [251 139]]\n",
            "\n",
            "TEST METRICS ----------------------\n",
            "Accuracy: 59.13461538461539%\n",
            "Precision: 97.2027972027972%\n",
            "Recall: 35.64102564102564%\n",
            "F1-score: 52.15759849906192\n",
            "\n",
            "TRAIN METRIC ----------------------\n",
            "Train acc: 81.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um8OceVqM4KK"
      },
      "source": [
        "from keras.preprocessing import image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1QfXWpqKN1O"
      },
      "source": [
        "img = plt.imread('chest_xray/val/PNEUMONIA/person1954_bacteria_4886.jpeg')\n",
        "img = cv2.resize(img, (img_dims, img_dims))\n",
        "img = np.dstack([img, img, img])\n",
        "img = img.astype('float32') / 255\n",
        "result = model.predict(np.expand_dims(image.img_to_array(img), axis = 0))  \n",
        "\n",
        "if result[0][0] > 0.5:\n",
        "  prediction = 'Pnuemonia'\n",
        "else:\n",
        "  prediction = 'Normal'\n",
        "  \n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVHufourySh0",
        "outputId": "2f317cbe-5855-49fb-fc31-b539b51e966d"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\ajith'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQAShWV7eyP3"
      },
      "source": [
        "IMAGE CONVERSION FROM DICOM TO **JPG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs7BqLvOMm5q"
      },
      "source": [
        "import pydicom as dicom\n",
        "import os\n",
        "import cv2\n",
        "#import PIL # optional\n",
        "# make it True if you want in PNG format\n",
        "PNG = False\n",
        "# Specify the .dcm folder path\n",
        "\n",
        "folder_path = \"rsna-pneumonia-detection-challenge/stage_2_test_images\"\n",
        "# Specify the output jpg/png folder path\n",
        "jpg_folder_path = \"rsna-pneumonia-detection-challenge/test\"\n",
        "images_path = os.listdir(folder_path)\n",
        "for n, image in enumerate(images_path):\n",
        "    ds = dicom.dcmread(os.path.join(folder_path, image))\n",
        "    pixel_array_numpy = ds.pixel_array\n",
        "    if PNG == False:\n",
        "        image = image.replace('.dcm', '.jpg')\n",
        "    else:\n",
        "        image = image.replace('.dcm', '.png')\n",
        "    cv2.imwrite(os.path.join(jpg_folder_path, image), pixel_array_numpy)\n",
        "    if n % 50 == 0:\n",
        "        print('{} image converted'.format(n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w74Hulu8yn_E",
        "outputId": "5ba93b62-5487-4aad-c31d-541b950c9730"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 150, 150, 16)      2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 16)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_1 (Separabl (None, 75, 75, 32)        688       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_2 (Separabl (None, 75, 75, 32)        1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 75, 75, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_3 (Separabl (None, 37, 37, 64)        2400      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 37, 37, 64)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 37, 37, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_5 (Separabl (None, 18, 18, 128)       8896      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_6 (Separabl (None, 18, 18, 128)       17664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 18, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 9, 9, 256)         34176     \n",
            "_________________________________________________________________\n",
            "separable_conv2d_8 (Separabl (None, 9, 9, 256)         68096     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 9, 9, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,314,337\n",
            "Trainable params: 2,313,377\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTWDK14Qgbsb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}